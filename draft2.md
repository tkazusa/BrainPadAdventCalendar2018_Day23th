# TL;DR
マイクロサービス基盤がない、潤沢にエンジニアリソースがない、そんな現場にも機械学習プロジェクトをいい感じにプロダクトに乗せていく今風のやり方について考えたい。そのために現状世の中にある機械学習ツールを俯瞰したい。
プロダクトに乗せるとすると、デプロイで終わりではなくて、モデル再学習やモニタリングなども含めて考えたい。

# はじめに
- 機械学習のサービスは内部のアルゴリズムが複雑であっても、そのサービス自体に求められることが多くなかったり、学習と推論時で必要なリソースが異なったりというところからマイクロサービスアーキテクチャと相性が良いと言われている。
- 実際機械学習について意欲的に取り組んでいる企業、特にWeb系企業では既にマイクロサービスアーキテクチャを採用した基盤があり、その上で効率的に機械学習モデルをデプロイするための方法を検討している。
- 一方で、そうでない現場で機械学習をプロダクトに載せる知見が溜まっていないように感じる。
- モデル開発や最初のデプロイはもちろん、その後、少ないエンジニアリソースでも機械学習モデルを継続的に使っていくためには、どのようなツールをどのように組み合わせていくのが良いのか考えたい。正直、ビジネス要件に依る部分も大きいので決めきれるもんではないけど、少なくとも選択肢は知っておきたい。

# 本当に何も無い現場で始めるMLプロダクト
- 機械学習は小さく初めて試行錯誤し、少しずつプロダクトに仕上げていく進め方が良いのではと思います。
  - 新しい取り組みであり、開発者もユーザーも機械学習によって何がどの程度できるようになるのかわかっていない
  - 機械学習モデルの精度によって、ユーザーとプロダクトの関わり方が変わってくる
  - 運用の技術的習熟が必要となる、新しい技術が多く出てくる＆データの質が時間の経過と共に変化する可能性があるから。
  
- じゃあ機械学習をインフラも含めたプロダクト全体を、イチから小さく開発するための今風のやり方って何？デプロイとモデルのメンテナンスという観点から見ていきたい。
## デプロイ観点
アドカレに["機械学習プロジェクトをいい感じにプロダクトに載せていく今風のやり方について考える"](https://aflc.qrunch.io/entries/dQqtdFHRumPAYJcj)という記事にアプリへのモデルの組み込み方が整理されいたました。デプロイという観点ではこの中の①や②、③が本当に何も無い現場で機械学習プロダクトを開発するには良さそうなパターンに見えます。

```
2. モデルをWeb application framework（Flaskなど）で包んでAPIサーバーを作る
3. モデルをWeb application framework（Flaskなど）で包んでコンテナイメージ化し、AWS Fargate、Azure Container Instance, (Managed) Kubernetesなどで管理する
```

## モデルメンテナンス観点
  - 機械学習モデルの運用は、といったことが必要になる。
    - データの確認
    - モデルの再学習/実験
    - モデルの評価
    - 再デプロイ
 - スモールスタートで始めたばかりの機械学習プロジェクトであれば、パイプラインはシンプルなはず。けど、運用する人を貼り付けておくほどリソースはない場合が多いのではないでしょうか。
 

よって、「API化された機械学習モデルがデプロイされているようなサービング環境において、シンプルなイプラインを手間をかけずに構築＆維持し、継続的にMlを活用し続ける」ことを助けられるツールを探してみましょう。機械学習モデルを開発し、Webサービスとして提供するために必要そうなコンポーネントは以下あたりでしょう。
- 開発環境: Jupyter: ある程度開発し、運用に乗ると毎日改良を重ねるようなことは少なくなるのではないでしょうか。だとするとクラウドサービスを活用した方が、初期環境構築の手間など削減できて良さそう。SageMaker, Datalab, colab
- preprocess: 機械学習モデルへデータを学習させるまでのデータの加工部分です。モデルデプロイの後、推論の流すためのデータを処理したり、再学習時の処理の再に必要です。SQLで処理したり、pythonスクリプトで良いじゃんってのもありますが、場合によってはDataflow, Amazon Batchなどの使用も選択肢に。
- 学習環境: 機械学習モデルの学習は推論時よりも計算リソースがかかることが多いため、こちらもクラウドサービスでアドホックに使うのが良いのではないでしょうか。また、学習時のハイパラ調整や特徴量選択などの実験結果の記録を残しておくことは、プロダクト全体の保守性の観点からは重要となるでしょう。
- デプロイ:  
- タスクランナー: 上記のようなデータの取得から前処理、学習、デプロイといった機械学習プロダクトの全体のワークフローを属人化させないためにシンプルであってもタスクランナーが重要となるでしょう。機械学習モデルを「作った人しかメンテナンスできない」は最悪の状態です。


## クラウドサービスを組み合わせるパターン
- 開発環境: Sagemaker, Datalab, Colaboratory
  - Jupyterのインスタンスが立ち上がる
- Preprocess: BQ, Redshift, Dataflow, Batchなど
  - DataflowがBeamなの面白い。
- 学習環境: SagemakerのXX, Datalab, Colaboratory, MLE
  - TFjob書かせるのめんどくさい。jupyterでそのまま学習させてしまうのもある。FBlearner?けど、jupyterそのまんまでちゃんとしたワークフロー流せるようになるためには結構な工夫が必要そうで、そのための基盤づくりはそれなりに大変そう
- Deploy: Sagemaker, MLE
- タスクランナー: Airflow
  - AWSで統合が進んでいたり、もともとAirflowはGoogleが開発していたりで良さげ。

− AWS, GCPでクラウドサービスを組み合わせ、デプロイ後の運用においてはAirflowでタスクを定義してやる。で良さげ。ただし抜けているのが、下記。
  - いつ、どのような試行錯誤を実施し、どのような結果になったのかが、運用者以外の第三者でもわかるようになっていること
  - データ自体の版管理。ここは機械学習プロダクトの鬼門ではないか。シンプルなプロダクトにおいては、特定のディレクトリやDBから任意のデータを引っ張ってくるようなことをしがちだが、同じ名前だからといって同じデータとは限らない。どこまでコストをかけてチェックするかは悩みどころ。
  

  
  - https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-dg.pdf
  - その気になれば開発、学習、サービングの全部ができる
  - 最近Airflowと統合を発表。preprocessどうするんだろう？
    - データのパイプラインジャングルと戦うという意味ではAmazon Batchとの組み合わせ必要そう
  - Airflowとの統合あったぽいhttps://airflow.readthedocs.io/en/stable/_modules/airflow/contrib/operators/awsbatch_operator.htm


- [mlflow](https://www.mlflow.org/docs/latest/tracking.html)はDatabricksから提供されている、機械学習モデルのライフサイクルをE2Eで管理するためのツールです。
- 主に、モデル構築の実験を一覧性を持って記録してくれるMLflow Traking、パイプラインそのものをパッケージにしてしまい再利用可能にするためのMLflow Projects、機械学習モデルをサービングするためにフォーマットしてくれるMLflow Modelsの3つのコンポーネントがあります。
- この中でML Trackingは割と手軽に実験の結果のログを残してくれるのツールとして期待しています。下記のように記録したい対象を設定してやるだけ。
- 同様の機能は例えばSagemakerであればハイパラの自動チューニングの結果表示として使ってやる必要があり、カスタムのDockerをアップロードしてやるなど、多少手間がかかる印象です。
- MLflowの他の機能としては、Projectsはタスクランナーの位置づけ、ModelsはSagemakerやCMLEの位置づけにありますが、敢えてマイナーかつベータ版であるmlflowを使うことはエンジニアリソースの少ない環境ではハマりポイントになりそうです。一方で、MLflow Trackingは現状でMLのパイプライン全体に影響は及ばさず、仮にこれが動かなくても機械学習機能をサービスすることができる点も実運用の観点からは大きいのではないでしょうか。
- 実際にクラウドサービスを中心にパイプラインを構築した上で、学習の実験管理の部分だけMLflowにしたものを試している[^1]
 
 
 
 ### kubeflow pipeline
Kubeflow pipelinesはKubeflowの新しいコンポーネントであり、機械学習システムのワークフローを管理できるツールです。Kubernetes上に機械学習モデルを開発&プロダクトに乗せて運用するための様々なコンポーネントが展開されます。

- 開発環境: JupyterHunが立ち上がるのでその上で開発。
- Preprocess: 特徴的なのは、TFX[^2]のいちコンポーネントであるTensorflow Transform(TFT)を使えるところでしょう。さらに、その設定項目に"preprocess-mode"というものがあり、Kubernetes上ではなくDataflow上で動作させることもできます。そこまでやらんでいいやん、みたいなところありそうですけど。
- 学習環境: こちらも特徴的なのが[TFjob](https://www.kubeflow.org/docs/guides/components/tftraining/)というKubernetesのcustom resourceを活用して分散学習を定義することも可能なところ。
- Deploy: Kuberenetes上にTensorFlow Serving上にデプロイしたり、ML EngineのPrediction serviceに展開できたりします。
- タスクランナー: [Argo](https://argoproj.github.io/)がベースとなっているワークフローエンジンが使われています。ワークフローの定義はPythonをベースにしたDSLで記述し、その中でTFXのコンポーネントを活用する事ができます。


ワークフローごとに異なる設定をして実験(Experiment)を実施したログが残せたり、ワークフローがちゃんと動いているかモニタリングができるようになっていたりと、機会学習システムのモデリング以外に必要な機能が整備されています。ワークフローマネジメント自体はKubeflowのCoreComponentである、Argoが動いているらしいですが、UIが整ったことでやっと統一感があるpipeline管理ツールが出てきたなというところです。とは言え、ちょっと重厚感強すぎて何もないところから始める機械学習プロジェクトでは気軽には取り掛かれない印象ですね。既に基盤とエンジニアが整っているWeb系企業向けでしょうか。

# まとめ
世の中にツールが乱立して、自分自身の認識もとっ散らかってきた感ありますたので、調べがてらまとめました。レポートにもならない感想文みたいな記事になってしまいましたが、ご参考に頂ければ幸いです。





   [^1]:テスト
