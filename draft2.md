# TL;DR
マイクロサービス基盤がない、潤沢にエンジニアリソースがない、そんな現場にも機械学習プロジェクトをいい感じにプロダクトに乗せていく今風のやり方について考えたい。そのために現状世の中にある機械学習ツールを俯瞰したい。

# はじめに
- 機械学習のサービスは内部のアルゴリズムが複雑であっても、そのサービス自体に求められることが多くなかったり、学習と推論時で必要なリソースが異なったりというところからマイクロサービスアーキテクチャと相性が良いと言われている。
- 実際機械学習について意欲的に取り組んでいる企業、特にWeb系企業では既にマイクロサービスアーキテクチャを採用した基盤があり、その上で効率的に機械学習モデルをデプロイするための方法を検討している
- 一方で、そうでない現場で機械学習をプロダクトに載せる知見が溜まっていないように感じる。
- モデル開発や、初手のデプロイはもちろん、その後、少ないエンジニアリソースでも機械学習モデルを継続的に使っていくためには、どのようなツールをどのように組み合わせていくのが良いのか考えたい。

# 本当に何も無い現場で始めるMLプロダクト
- 機械学習は小さく初めて試行錯誤し、少しずつプロダクトに仕上げていく進め方が良いのではと思います。
  - 新しい取り組みであり、開発者もユーザーも機械学習によって何がどの程度できるようになるのかわかっていない
  - 機械学習モデルの精度によって、ユーザーとプロダクトの関わり方が変わってくる
  - 運用の技術的習熟が必要となる、新しい技術が多く出てくる＆データの質が時間の経過と共に変化する可能性があるから。
  
- じゃあ機械学習をインフラも含めたプロダクト全体を、イチから小さく開発するための今風のやり方って何？
- デプロイとモデルのメンテナンスという観点から見ていきたい。
　-　アドカレに["機械学習プロジェクトをいい感じにプロダクトに載せていく今風のやり方について考える"](https://aflc.qrunch.io/entries/dQqtdFHRumPAYJcj)という記事にアプリへのモデルの組み込み方が整理されいたました。
- デプロイという観点ではこの中の①や②、③が本当に何も無い現場で機械学習プロダクトを開発するには良さそうなパターンに見えます。
- 機械学習モデルの運用は、といったことが必要になる。
  - データの確認
  - モデルの再学習/実験
  - モデルの評価
  - デプロイ
- スモールスタートで始めたばかりの機械学習プロジェクトであれば、パイプラインはシンプルなはず。けど、運用する人を貼り付けておくほどリソースはない場合が多い。

- "シンプルな機械学習モデル開発のパイプラインを手間をかけずに構築＆維持し、継続的にMlを活用し続ける”ことを助けられるツールが良さそう。
- パイプラインの参考となるのはTFXか。
  - TFXの図
- この流れを全部の機能とは言わずに、手軽に作りたい

# 候補になりそうなもの
 - Airflow + Sagemaker
  − https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-dg.pdf
  - その気になれば開発、学習、サービングの全部ができる
  - 最近Airflowと統合を発表。preprocessどうするんだろう？
  - データのパイプラインジャングルと戦うという意味ではAmazon Batchとの組み合わせ必要そう
    - Airflowとの統合あったぽいhttps://airflow.readthedocs.io/en/stable/_modules/airflow/contrib/operators/awsbatch_operator.html

- Aifrlow + mlflow + クラウドサービングサービス
  - 実験の管理が充実している
  - mlflowの他の機能使えばもう少しリッチになるかも
 
 − kubeflow pipeline
  
  
  
  
  
  
  
