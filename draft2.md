# TL;DR
マイクロサービス基盤がない、潤沢にエンジニアリソースがない、そんな現場にも機械学習プロジェクトをいい感じにプロダクトに乗せていく今風のやり方について考えたい。そのために現状世の中にある機械学習ツールを俯瞰したい。
プロダクトに乗せるとすると、デプロイで終わりではなくて、モデル再学習やモニタリングなども含めて考えたい。

# はじめに
- 機械学習のサービスは内部のアルゴリズムが複雑であっても、そのサービス自体に求められることが多くなかったり、学習と推論時で必要なリソースが異なったりというところからマイクロサービスアーキテクチャと相性が良いと言われている。
- 実際機械学習について意欲的に取り組んでいる企業、特にWeb系企業では既にマイクロサービスアーキテクチャを採用した基盤があり、その上で効率的に機械学習モデルをデプロイするための方法を検討している。
- 一方で、そうでない現場で機械学習をプロダクトに載せる知見が溜まっていないように感じる。
- モデル開発や最初のデプロイはもちろん、その後、少ないエンジニアリソースでも機械学習モデルを継続的に使っていくためには、どのようなツールをどのように組み合わせていくのが良いのか考えたい。正直、ビジネス要件に依る部分も大きいので決めきれるもんではないけど、少なくとも選択肢は知っておきたい。

# 本当に何も無い現場で始めるMLプロダクト
- 機械学習は小さく初めて試行錯誤し、少しずつプロダクトに仕上げていく進め方が良いのではと思います。
  - 新しい取り組みであり、開発者もユーザーも機械学習によって何がどの程度できるようになるのかわかっていない
  - 機械学習モデルの精度によって、ユーザーとプロダクトの関わり方が変わってくる
  - 運用の技術的習熟が必要となる、新しい技術が多く出てくる＆データの質が時間の経過と共に変化する可能性があるから。
  
- じゃあ機械学習をインフラも含めたプロダクト全体を、イチから小さく開発するための今風のやり方って何？デプロイとモデルのメンテナンスという観点から見ていきたい。
## デプロイ観点
アドカレに["機械学習プロジェクトをいい感じにプロダクトに載せていく今風のやり方について考える"](https://aflc.qrunch.io/entries/dQqtdFHRumPAYJcj)という記事にアプリへのモデルの組み込み方が整理されいたました。デプロイという観点ではこの中の①や②、③が本当に何も無い現場で機械学習プロダクトを開発するには良さそうなパターンに見えます。

```
2. モデルをWeb application framework（Flaskなど）で包んでAPIサーバーを作る
3. モデルをWeb application framework（Flaskなど）で包んでコンテナイメージ化し、AWS Fargate、Azure Container Instance, (Managed) Kubernetesなどで管理する
```

## モデルメンテナンス観点
  - 機械学習モデルの運用は、といったことが必要になる。
    - データの確認
    - モデルの再学習/実験
    - モデルの評価
    - 再デプロイ
 - スモールスタートで始めたばかりの機械学習プロジェクトであれば、パイプラインはシンプルなはず。けど、運用する人を貼り付けておくほどリソースはない場合が多いのではないでしょうか。
 

よって、「API化された機械学習モデルがデプロイされているようなサービング環境において、シンプルなイプラインを手間をかけずに構築＆維持し、継続的にMlを活用し続ける」ことを助けられるツールを探してみましょう。機械学習モデルを開発し、Webサービスとして提供するために必要そうなコンポーネントは以下あたりでしょう。
- 開発環境: Jupyter: ある程度開発し、運用に乗ると毎日改良を重ねるようなことは少なくなるのではないでしょうか。だとするとクラウドサービスを活用した方が、初期環境構築の手間など削減できて良さそう。SageMaker, Datalab, colab
- preprocess: 機械学習モデルへデータを学習させるまでのデータの加工部分です。モデルデプロイの後、推論の流すためのデータを処理したり、再学習時の処理の再に必要です。SQLで処理したり、pythonスクリプトで良いじゃんってのもありますが、場合によってはDataflow, Amazon Batchなどの使用も選択肢に。
- 学習環境: 機械学習モデルの学習は推論時よりも計算リソースがかかることが多いため、こちらもクラウドサービスでアドホックに使うのが良いのではないでしょうか。また、学習時のハイパラ調整や特徴量選択などの実験結果の記録を残しておくことは、プロダクト全体の保守性の観点からは重要となるでしょう。
- デプロイ:  
- タスクランナー: 上記のようなデータの取得から前処理、学習、デプロイといった機械学習プロダクトの全体のワークフローを属人化させないためにシンプルであってもタスクランナーが重要となるでしょう。機械学習モデルを「作った人しかメンテナンスできない」は最悪の状態です。



## クラウドサービスを組み合わせるパターン
- 開発環境: Sagemaker, Datalab, Colaboratory
  - Jupyterのインスタンスが立ち上がる
- Preprocess: BQ, Redshift, Dataflow, Batchなど
  - DataflowがBeamなの面白い。
- 
- Airflow + Sagemaker + Amazon Batch
- Airflow + Dataflow + MLE
  - https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-dg.pdf
  - その気になれば開発、学習、サービングの全部ができる
  - 最近Airflowと統合を発表。preprocessどうするんだろう？
    - データのパイプラインジャングルと戦うという意味ではAmazon Batchとの組み合わせ必要そう
  - Airflowとの統合あったぽいhttps://airflow.readthedocs.io/en/stable/_modules/airflow/contrib/operators/awsbatch_operator.htm



- mlflow 単体
  - 組み合わせでOK？
  - 実際そうしている: 家入記事

 − kubeflow pipeline
